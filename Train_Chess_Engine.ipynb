{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "Jl9ZpNSMpMYw"
      },
      "source": [
        "# Python Chess Engine Train"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/iAmEthanMai/chess-engine-model/blob/main/train_chess_engine.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## START of Notebook"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Execution started on 26-05-2023 at 12:52:01\n",
            "time: 292 Âµs (started: 2023-05-26 12:52:01 +05:30)\n"
          ]
        }
      ],
      "source": [
        "%load_ext autotime\n",
        "\n",
        "from datetime import datetime\n",
        "\n",
        "start_time = datetime.now()\n",
        "print(f\"Execution started on {start_time.strftime('%d-%m-%Y at %H:%M:%S')}\")"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Environement Settings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "BFciLyCHgTvO"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "time: 2.17 s (started: 2023-05-26 12:52:01 +05:30)\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "import pandas as pd\n",
        "\n",
        "from enum import Enum\n",
        "from pathlib import Path\n",
        "from tensorflow import estimator, feature_column\n",
        "from tqdm.auto import tqdm\n",
        "from typing import List\n",
        "from zipfile import ZipFile"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "f_3vxIeTp1MN"
      },
      "source": [
        "## Data\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "time: 1.54 s (started: 2023-05-26 13:01:26 +05:30)\n"
          ]
        }
      ],
      "source": [
        "base_path = Path.cwd()\n",
        "dataset_zip_file = base_path.joinpath('Datasets.zip')\n",
        "with ZipFile(dataset_zip_file, 'r') as zip_ref:\n",
        "    zip_ref.extractall(base_path)\n",
        "chess_moves_dataset_path = base_path.joinpath('Datasets')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class ChessMovesDatasets(Enum):\n",
        "    FISCHER = chess_moves_dataset_path.joinpath('FISCHER')\n",
        "    MORPHY = chess_moves_dataset_path.joinpath('MORPHY')\n",
        "    CAPABLANCA = chess_moves_dataset_path.joinpath('CAPABLANCA')\n",
        "\n",
        "    @classmethod\n",
        "    def keys(cls) -> List[str]:\n",
        "        \"\"\"Returns a list of all the enum keys.\"\"\"\n",
        "        return cls._member_names_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xSiXhMHNggxe"
      },
      "outputs": [],
      "source": [
        "# chess_moves_files = ChessMovesDatasets.FISCHER.value.glob(\"*.csv\")\n",
        "chess_moves_files = chess_moves_dataset_path.glob(\"**/*.csv\")\n",
        "\n",
        "train = pd.concat(map(pd.read_csv, chess_moves_files))\n",
        "train.sample(frac=1, random_state=42).reset_index(drop=True, inplace=True)\n",
        "\n",
        "# Fill None values to blank values\n",
        "train.fillna('', inplace=True)\n",
        "\n",
        "print(f\"Shape of the training data: {train.shape}\")\n",
        "display(train.head())"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "3eS-CxibqwBN"
      },
      "source": [
        "## Features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-jz-tMDPg8TY"
      },
      "outputs": [],
      "source": [
        "feature_cols = list(train.iloc[:, 0:192].columns)\n",
        "target_col = 'good_move'\n",
        "X = train.drop(target_col, axis=1)\n",
        "y = train['good_move']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8x5dhguuhDhM"
      },
      "outputs": [],
      "source": [
        "categorical_columns = list(X.iloc[:, 0:63].columns)\n",
        "numerical_columns = list(X.iloc[:, 64:192].columns)\n",
        "feature_columns = []\n",
        "\n",
        "for feature_name in categorical_columns:\n",
        "    vocabulary = X[feature_name].unique()\n",
        "    feature_columns.append(tf.feature_column.categorical_column_with_vocabulary_list(feature_name, vocabulary))\n",
        "\n",
        "\n",
        "for feature_name in numerical_columns:\n",
        "    feature_columns.append(tf.feature_column.numeric_column(feature_name,dtype = tf.float32))"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "6L8CbTnMsCKD"
      },
      "source": [
        "## Input Function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0z_ETx3yhInr"
      },
      "outputs": [],
      "source": [
        "def make_input_fn(data_df, label_df, num_epochs = 10, shuffle = True, batch_size = 32):\n",
        "    def input_function():\n",
        "        ds = tf.data.Dataset.from_tensor_slices((dict(data_df), label_df))\n",
        "        if shuffle:\n",
        "            ds = ds.shuffle(1000)\n",
        "        ds = ds.batch(batch_size).repeat(num_epochs)\n",
        "        return ds\n",
        "    return input_function"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "EjsegLZzupXr"
      },
      "source": [
        "## Split Data into Batches"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x2YoZFeFux0W"
      },
      "outputs": [],
      "source": [
        "def split_into_batches(df, batch_size=100000):\n",
        "    nb_rows = len(df.index)\n",
        "    intervals = []\n",
        "    \n",
        "    for i in range(0, nb_rows + 1, batch_size):\n",
        "        intervals.append(i)\n",
        "    \n",
        "    if(intervals[-1] != nb_rows):\n",
        "        intervals.append(nb_rows)\n",
        "    \n",
        "    batches_X = []\n",
        "    batches_y = []\n",
        "    \n",
        "    for i in range(0, len(intervals) - 1):\n",
        "        batches_X.append(train.iloc[intervals[i]:intervals[i + 1], :][feature_cols])\n",
        "        batches_y.append(train.iloc[intervals[i]:intervals[i + 1], :][target_col])\n",
        "\n",
        "    return batches_X, batches_y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e_bCFyfXzNgI"
      },
      "outputs": [],
      "source": [
        "batches_X, batches_y = split_into_batches(train)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "p312bOtf3gry"
      },
      "source": [
        "## Model Training "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "40Z0jdfnhQKp",
        "outputId": "40d49c7d-fdb7-4503-983d-2358cad28954"
      },
      "outputs": [],
      "source": [
        "dt = datetime.now().strftime('%Y-%m-%d')\n",
        "estimator_path = base_path.joinpath(f'Estimator/{dt}')\n",
        "linear_est = estimator.LinearClassifier(feature_columns=feature_columns, model_dir=estimator_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GRQFWso4zRj-"
      },
      "outputs": [],
      "source": [
        "input_functions = []\n",
        "for df_X, df_y in zip(batches_X, batches_y):\n",
        "    input_functions.append(make_input_fn(df_X, df_y))\n",
        "\n",
        "print(f\"Length of Input Functions: {len(input_functions)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M8m7e7OV3Ol6"
      },
      "outputs": [],
      "source": [
        "# Train the model on all the input functions\n",
        "training_pbar = tqdm(input_functions)\n",
        "for idx, input_function in enumerate(training_pbar, start=1):\n",
        "    training_pbar.set_description(f'Batch: {idx}')\n",
        "    linear_est.train(input_function)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Save the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "serving_input_fn = estimator.export.build_parsing_serving_input_receiver_fn(\n",
        "                                        feature_column.make_parse_example_spec(feature_columns))\n",
        "\n",
        "estimator_path = linear_est.export_saved_model(estimator_path, serving_input_fn)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## END of Notebook"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "end_time = datetime.now()\n",
        "print(f\"Execution ended on {end_time.strftime('%d-%m-%Y at %H:%M:%S')}\")\n",
        "print(f\"Total Execution Time: {str(end_time - start_time)}\")\n",
        "\n",
        "%unload_ext autotime"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "authorship_tag": "ABX9TyPVxseL6+b+V8iLTeFD71UJ",
      "collapsed_sections": [],
      "include_colab_link": true,
      "name": "train-chess-engine.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
